{"cells":[{"cell_type":"markdown","metadata":{"id":"ML_yvSbJ-dRC"},"source":["## Data preparation WORK"]},{"cell_type":"markdown","metadata":{"id":"Xl1q4Xu4CCFE"},"source":["**Change according to your configuration, and environment**\n","\n","**Make sure there the 'scripts' folder and 'data' folder are presents.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpIktIWCBhNC","trusted":true},"outputs":[],"source":["!git clone https://github.com/gjuuuy/MT_base.git"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd MT_base"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj5nn1CW9vJd","trusted":true},"outputs":[],"source":["%pip install datasets OpenNMT-py==3.0.0 sentencepiece torch==1.12.1\n","%pip install https://github.com/RobotsMali-AI/rmai/releases/download/0.0.4/rmaipkg-0.0.4.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPyQBZFL-Hdx","trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"RobotsMaliAI/bayelemabaga\", \"bam-fr\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzIOFbrW-aGJ","trusted":true},"outputs":[],"source":["def decompose_dataset(dset):\n","  out = {\"train\": [], \"validation\": [], \"test\": []}\n","  for k in out:\n","    values = [(i[\"bam\"], i[\"fr\"]) for i in dset[k][\"translation\"]]\n","    out[k] = values\n","  out[\"dev\"] = out[\"validation\"]\n","  del out[\"validation\"]\n","  return out\n","\n","def write_x(path, data):\n","  with open(path, \"w\") as fp:\n","    for i in data:\n","      fp.write(f\"{i}\\n\")\n","\n","def write_to_fs(dt_tuple, name):\n","  bam, fr = zip(*dt_tuple)\n","  write_x(f\"data/{name}.bam\", bam)\n","  write_x(f\"data/{name}.fr\", fr)\n","\n","out = decompose_dataset(dataset)\n","train = out[\"train\"]\n","dev = out[\"dev\"]\n","test = out[\"test\"]\n","\n","write_to_fs(train, \"train\")\n","write_to_fs(dev, \"dev\")\n","write_to_fs(test, \"test\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2I93bn6Egqq","trusted":true},"outputs":[],"source":["!bash scripts/prepare.sh data/train.bam data/train.fr 80000 unigram"]},{"cell_type":"markdown","metadata":{"id":"31VoxzGqHY8d"},"source":["## Model / Training Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6KKFqB0HeaH","trusted":true},"outputs":[],"source":["import os\n","\n","model_name = \"bam2fr\"\n","vocab_size = 50000\n","\n","training_steps = 1000\n","valid_steps = int(training_steps / 5)\n","save_ckpt_freq = int(training_steps / 5)\n","warmup_steps = int(training_steps / 100)\n","reporting = int(training_steps/1000)\n","GPU = 1 # TOGGLE for GPU\n","\n","if(not os.path.exists(model_name)):\n","  os.makedirs(model_name)\n","\n","config = f\"\"\"\n","\n","## Where the samples will be written\n","save_data: {model_name}/run\n","\n","overwrite: True # Toggle this for rewritting\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: data/train.sub-src.txt\n","        path_tgt: data/train.sub-trg.txt\n","        transforms: []\n","    valid:\n","        path_src: data/dev.sub-src.txt\n","        path_tgt: data/dev.sub-trg.txt\n","        transforms: []\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: {model_name}/source.vocab\n","tgt_vocab: {model_name}/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: {vocab_size}\n","tgt_vocab_size: {vocab_size}\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: data/source.model\n","tgt_subword_model: data/target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: {model_name}/train.log\n","save_model: {model_name}/models/{model_name}\n","\n","# Stop training if it does not improve after n validations\n","early_stopping: 3\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: {save_ckpt_freq}\n","\n","# To save space, limit checkpoints to last n\n","keep_checkpoint: 2\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps \n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: {training_steps}\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: {valid_steps}\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: {warmup_steps}\n","report_every: {reporting}\n","\n","tensorboard: true\n","tensorboard_log_dir: {model_name}\n","\n","# Number of GPUs, and IDs of GPUs\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","\n","\"\"\"\n","\n","if(GPU):\n","    config += \"\"\"\n","world_size: 2\n","gpu_ranks: [0,1]\n","\"\"\"\n","\n","with open(f\"{model_name}/config.yaml\", \"w\") as fp:\n","  fp.write(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%reload_ext tensorboard\n","\n","%tensorboard --logdir bam2fr/"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!head -n10 data/train.sub-src.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!head -n10 data/train.sub-trg.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv8QoZU5TZ8l","trusted":true},"outputs":[],"source":["!onmt_build_vocab -c bam2fr/config.yaml -n_sample -1 --dump_samples # -1 full corpus, bpe, sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!export CUDA_VISIBLE_DEVICES=0,1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HQ3cHg9VItn","trusted":true},"outputs":[],"source":["!onmt_train -config bam2fr/config.yaml --verbose"]},{"cell_type":"markdown","metadata":{"id":"kQHRzhIEZTRC"},"source":["## Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-qSMFQ0Za3T","trusted":true},"outputs":[],"source":["!onmt_translate -model bam2fr/models/bam2fr_step_40000.pt -src data/test.sub-src.txt -output bam2fr/models/pred_40000.txt -gpu 1 -verbose"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45lJ9vy6y5w1","trusted":true},"outputs":[],"source":["!python scripts/desubword.py data/target.model bam2fr/models/pred_40000.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47sp8qSWAt6q","trusted":true},"outputs":[],"source":["# Sacrebleu testing CODE\n","bleu = !sacrebleu data/test.fr -i bam2fr/models/pred_40000.txt.desub.txt -m bleu -b -w 4\n","ter = !sacrebleu data/test.fr -i bam2fr/models/pred_40000.txt.desub.txt -m ter -b -w 4\n","\n","print(bleu)\n","print(ter)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls bam2fr/models/"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'bam2fr/models/pred_40000.txt.desub.txt')"]},{"cell_type":"markdown","metadata":{},"source":["## Export Model (When done)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r mt_base.zip MT_base"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["FileLink(r'mt_base.zip')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM6b4yS0zDXa9ZLcWoPg/na","mount_file_id":"1Un-ObQG6c9zQN03nq4ugkDzCNOblwyve","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
