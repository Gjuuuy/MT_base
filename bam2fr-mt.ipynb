{"metadata":{"colab":{"authorship_tag":"ABX9TyM6b4yS0zDXa9ZLcWoPg/na","mount_file_id":"1Un-ObQG6c9zQN03nq4ugkDzCNOblwyve","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data preparation WORK","metadata":{"id":"ML_yvSbJ-dRC"}},{"cell_type":"markdown","source":"**Change according to your configuration, and environment**\n\n**Make sure there the 'scripts' folder and 'data' folder are presents.**","metadata":{"id":"Xl1q4Xu4CCFE"}},{"cell_type":"code","source":"!git clone https://github.com/gjuuuy/MT_base.git","metadata":{"id":"xpIktIWCBhNC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd MT_base","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install datasets OpenNMT-py==3.0.0 sentencepiece torch==1.12.1\n%pip install https://github.com/RobotsMali-AI/rmai/releases/download/0.0.4/rmaipkg-0.0.4.tar.gz","metadata":{"id":"Tj5nn1CW9vJd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"RobotsMaliAI/bayelemabaga\", \"bam-fr\")","metadata":{"id":"qPyQBZFL-Hdx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decompose_dataset(dset):\n  out = {\"train\": [], \"validation\": [], \"test\": []}\n  for k in out:\n    values = [(i[\"bam\"], i[\"fr\"]) for i in dset[k][\"translation\"]]\n    out[k] = values\n  out[\"dev\"] = out[\"validation\"]\n  del out[\"validation\"]\n  return out\n\ndef write_x(path, data):\n  with open(path, \"w\") as fp:\n    for i in data:\n      fp.write(f\"{i}\\n\")\n\ndef write_to_fs(dt_tuple, name):\n  bam, fr = zip(*dt_tuple)\n  write_x(f\"data/{name}.bam\", bam)\n  write_x(f\"data/{name}.fr\", fr)\n\nout = decompose_dataset(dataset)\ntrain = out[\"train\"]\ndev = out[\"dev\"]\ntest = out[\"test\"]\n\nwrite_to_fs(train, \"train\")\nwrite_to_fs(dev, \"dev\")\nwrite_to_fs(test, \"test\")\n","metadata":{"id":"TzIOFbrW-aGJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!bash scripts/prepare.sh data/train.bam data/train.fr 80000 unigram","metadata":{"id":"X2I93bn6Egqq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model / Training Configuration","metadata":{"id":"31VoxzGqHY8d"}},{"cell_type":"code","source":"import os\n\nmodel_name = \"bam2fr\"\nvocab_size = 50000\n\ntraining_steps = 1000\nvalid_steps = int(training_steps / 5)\nsave_ckpt_freq = int(training_steps / 5)\nwarmup_steps = int(training_steps / 100)\nreporting = int(training_steps/1000)\nGPU = 1 # TOGGLE for GPU\n\nif(not os.path.exists(model_name)):\n  os.makedirs(model_name)\n\nconfig = f\"\"\"\n\n## Where the samples will be written\nsave_data: {model_name}/run\n\noverwrite: True # Toggle this for rewritting\n\n# Training files\ndata:\n    corpus_1:\n        path_src: data/train.sub-src.txt\n        path_tgt: data/train.sub-trg.txt\n        transforms: []\n    valid:\n        path_src: data/dev.sub-src.txt\n        path_tgt: data/dev.sub-trg.txt\n        transforms: []\n\n# Vocabulary files, generated by onmt_build_vocab\nsrc_vocab: {model_name}/source.vocab\ntgt_vocab: {model_name}/target.vocab\n\n# Vocabulary size - should be the same as in sentence piece\nsrc_vocab_size: {vocab_size}\ntgt_vocab_size: {vocab_size}\n\n# Filter out source/target longer than n if [filtertoolong] enabled\nsrc_seq_length: 150\nsrc_seq_length: 150\n\n# Tokenization options\nsrc_subword_model: data/source.model\ntgt_subword_model: data/target.model\n\n# Where to save the log file and the output models/checkpoints\nlog_file: {model_name}/train.log\nsave_model: {model_name}/models/{model_name}\n\n# Stop training if it does not improve after n validations\nearly_stopping: 3\n\n# Default: 5000 - Save a model checkpoint for each n\nsave_checkpoint_steps: {save_ckpt_freq}\n\n# To save space, limit checkpoints to last n\nkeep_checkpoint: 2\n\nseed: 3435\n\n# Default: 100000 - Train the model to max n steps \n# Increase to 200000 or more for large datasets\n# For fine-tuning, add up the required steps to the original steps\ntrain_steps: {training_steps}\n\n# Default: 10000 - Run validation after n steps\nvalid_steps: {valid_steps}\n\n# Default: 4000 - for large datasets, try up to 8000\nwarmup_steps: {warmup_steps}\nreport_every: {reporting}\n\ntensorboard: true\ntensorboard_log_dir: {model_name}\n\n# Number of GPUs, and IDs of GPUs\n\n# Batching\nbucket_size: 262144\nnum_workers: 0  # Default: 2, set to 0 when RAM out of memory\nbatch_type: \"tokens\"\nbatch_size: 4096   # Tokens per batch, change when CUDA out of memory\nvalid_batch_size: 2048\nmax_generator_batches: 2\naccum_count: [4]\naccum_steps: [0]\n\n# Optimization\nmodel_dtype: \"fp16\"\noptim: \"adam\"\nlearning_rate: 2\n\n# warmup_steps: 8000\ndecay_method: \"noam\"\nadam_beta2: 0.998\nmax_grad_norm: 0\nlabel_smoothing: 0.1\nparam_init: 0\nparam_init_glorot: true\nnormalization: \"tokens\"\n\n# Model\nencoder_type: transformer\ndecoder_type: transformer\nposition_encoding: true\nenc_layers: 6\ndec_layers: 6\nheads: 8\nhidden_size: 512\nword_vec_size: 512\ntransformer_ff: 2048\ndropout_steps: [0]\ndropout: [0.1]\nattention_dropout: [0.1]\n\n\"\"\"\n\nif(GPU):\n    config += \"\"\"\nworld_size: 2\ngpu_ranks: [0,1]\n\"\"\"\n\nwith open(f\"{model_name}/config.yaml\", \"w\") as fp:\n  fp.write(config)","metadata":{"id":"F6KKFqB0HeaH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%reload_ext tensorboard\n\n%tensorboard --logdir bam2fr/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -n10 data/train.sub-src.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -n10 data/train.sub-trg.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!onmt_build_vocab -c bam2fr/config.yaml -n_sample -1 --dump_samples # -1 full corpus, bpe, sentencepiece","metadata":{"id":"Tv8QoZU5TZ8l","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export CUDA_VISIBLE_DEVICES=0,1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!onmt_train -config bam2fr/config.yaml --verbose","metadata":{"id":"7HQ3cHg9VItn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{"id":"kQHRzhIEZTRC"}},{"cell_type":"code","source":"!onmt_translate -model bam2fr/models/bam2fr_step_40000.pt -src data/test.sub-src.txt -output bam2fr/models/pred_40000.txt -gpu 1 -verbose","metadata":{"id":"e-qSMFQ0Za3T","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python scripts/desubword.py data/target.model bam2fr/models/pred_40000.txt","metadata":{"id":"45lJ9vy6y5w1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sacrebleu testing CODE\nbleu = !sacrebleu data/test.fr -i bam2fr/models/pred_40000.txt.desub.txt -m bleu -b -w 4\nter = !sacrebleu data/test.fr -i bam2fr/models/pred_40000.txt.desub.txt -m ter -b -w 4\n\nprint(bleu)\nprint(ter)","metadata":{"id":"47sp8qSWAt6q","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls bam2fr/models/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'bam2fr/models/pred_40000.txt.desub.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Export Model (When done)","metadata":{}},{"cell_type":"code","source":"%cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r mt_base.zip MT_base","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(r'mt_base.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}