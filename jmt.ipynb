{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szkoSLLuTjIl"
      },
      "outputs": [],
      "source": [
        "%pip install joeynmt subword_nmt sentencepiece # Main OpenNMT Package (No Need for subword_nmt sentencepiece)\n",
        "%pip install https://github.com/RobotsMali-AI/rmai/releases/download/0.0.4/rmaipkg-0.0.4.tar.gz # RobotsMaliAI's Datasets and Models\n",
        "%pip install https://github.com/s7d11/daba/releases/download/v0.0.1-alpha/daba-0.9.2.tar.gz # Non-UI Version of Daba\n",
        "%pip install sacrebleu # Redundant comes with OpenNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQGdTByjels-"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/joeynmt/joeynmt.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwLUJk4cY_zv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/gjuuuy/MT_base.git\n",
        "%cd MT_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0tTseDgTzSS"
      },
      "outputs": [],
      "source": [
        "from rmai.datasets.text import parallel\n",
        "\n",
        "#Afficher quelques textes parrallèle bamb-fr.\n",
        "text = parallel.get_text(max_len =500000 ,randomize = True)\n",
        "\n",
        "#Creér nos trainset et validset\n",
        "train, valid = parallel.random_split(text,90)\n",
        "\n",
        "test = valid[:360]\n",
        "valid = valid[360:]\n",
        "\n",
        "#Extraction du trainbam-fr et du validbam-fr\n",
        "extract = lambda x,dataset : [i[x] for i in dataset]\n",
        "\n",
        "train_bam = extract(0,train)\n",
        "train_fra = extract(1,train)\n",
        "\n",
        "valid_bam = extract(0,valid)\n",
        "valid_fra = extract(1,valid)\n",
        "\n",
        "test_bam = extract(0,test)\n",
        "test_fra = extract(1,test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SSRzD1NapKg"
      },
      "outputs": [],
      "source": [
        "#Eliminer les caractère superflues.\n",
        "parallel.write_to(lines = train_bam, name = 'trains',path = \"data\")\n",
        "parallel.write_to(lines = train_fra, name = 'traint',path = \"data\")\n",
        "parallel.write_to(lines = valid_bam, name = 'devs',path = \"data\")\n",
        "parallel.write_to(lines = valid_fra, name = 'devt',path = \"data\")\n",
        "parallel.write_to(lines = test_bam, name = 'tests',path = \"data\")\n",
        "parallel.write_to(lines = test_fra, name = 'testt',path = \"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGKettWMY_zz"
      },
      "outputs": [],
      "source": [
        "!wc data/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIG3dt3DT-S3"
      },
      "outputs": [],
      "source": [
        "!mv data/trains.txt data/train.bam\n",
        "!mv data/devs.txt data/dev.bam\n",
        "!mv data/tests.txt data/test.bam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX0epAKyY_z0"
      },
      "outputs": [],
      "source": [
        "!mv data/traint.txt data/train.fr\n",
        "!mv data/devt.txt data/dev.fr\n",
        "!mv data/testt.txt data/test.fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AmxfNTUycly"
      },
      "outputs": [],
      "source": [
        "!mkdir models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC7ImiGhYHAz"
      },
      "outputs": [],
      "source": [
        "config = f\"\"\"\n",
        "name: \"bam2fr\"\n",
        "\n",
        "data:\n",
        "    train: \"data/train\"\n",
        "    dev: \"data/dev\"\n",
        "    test: \"data/test\"\n",
        "    dataset_type: \"plain\"\n",
        "    #dataset_cfg:           # not necessary for manually saved pyarray daraset\n",
        "    #    name: \"de-en\"\n",
        "    sample_dev_subset: 200\n",
        "    src:\n",
        "        lang: \"bam\"\n",
        "        max_length: 100\n",
        "        lowercase: False\n",
        "        normalize: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 49039\n",
        "        voc_min_freq: 0\n",
        "        voc_file: \"data/vocab.txt\"\n",
        "        tokenizer_type: \"sentencepiece\"\n",
        "        tokenizer_cfg:\n",
        "            model_file: \"data/sp.model\"\n",
        "\n",
        "    trg:\n",
        "        lang: \"fr\"\n",
        "        max_length: 100\n",
        "        lowercase: False\n",
        "        normalize: False\n",
        "        level: \"bpe\"\n",
        "        voc_limit: 49039\n",
        "        voc_min_freq: 0\n",
        "        voc_file: \"data/vocab.txt\"\n",
        "        tokenizer_type: \"sentencepiece\"\n",
        "        tokenizer_cfg:\n",
        "            model_file: \"data/sp.model\"\n",
        "\n",
        "testing:\n",
        "    n_best: 1\n",
        "    beam_size: 5\n",
        "    beam_alpha: 1.0\n",
        "    batch_size: 256\n",
        "    batch_type: \"token\"\n",
        "    max_output_length: 100\n",
        "    eval_metrics: [\"bleu\"]\n",
        "    #return_prob: \"hyp\"\n",
        "    #return_attention: False\n",
        "    sacrebleu_cfg:\n",
        "        tokenize: \"13a\"\n",
        "\n",
        "training:\n",
        "    #load_model: \"models/latest.ckpt\"\n",
        "    #reset_best_ckpt: False\n",
        "    #reset_scheduler: False\n",
        "    #reset_optimizer: False\n",
        "    #reset_iter_state: False\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999]\n",
        "    scheduling: \"plateau\"\n",
        "    learning_rate_warmup: 1000\n",
        "    learning_rate: 0.0004\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.2\n",
        "    loss: \"crossentropy\"\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"bleu\"\n",
        "    epochs: 20\n",
        "    updates: 100000\n",
        "    validation_freq: 4000\n",
        "    logging_freq: 100\n",
        "    model_dir: \"models/bam2fr\"\n",
        "    overwrite: True\n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_best_ckpts: 2\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier_uniform\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier_uniform\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: False\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256\n",
        "        ff_size: 1024\n",
        "        dropout: 0.3\n",
        "        layer_norm: \"pre\"\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4\n",
        "        embeddings:\n",
        "            embedding_dim: 256\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256\n",
        "        ff_size: 1024\n",
        "        dropout: 0.3\n",
        "        layer_norm: \"pre\"\n",
        "        \"\"\"\n",
        "with open(\"config.yaml\",\"w\") as f : \n",
        "  f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qoRXK0dQnE"
      },
      "outputs": [],
      "source": [
        "#Vocab building.\n",
        "!wget https://raw.githubusercontent.com/joeynmt/joeynmt/v2.2/scripts/build_vocab.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTFc4Ju0dRls"
      },
      "outputs": [],
      "source": [
        "!python build_vocab.py config.yaml --joint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZtRFAgE1ZHo"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FT2V9DwD1cLy"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir models/bam2fr/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvyafjtnzJj4"
      },
      "outputs": [],
      "source": [
        "!python -m joeynmt train config.yaml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}