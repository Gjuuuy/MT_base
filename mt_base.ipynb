{"cells":[{"cell_type":"markdown","metadata":{"id":"ML_yvSbJ-dRC"},"source":["## Data preparation WORK"]},{"cell_type":"markdown","metadata":{"id":"Xl1q4Xu4CCFE"},"source":["**Change according to your configuration, and environment**\n","\n","**Make sure there the 'scripts' folder and 'data' folder are presents.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpIktIWCBhNC"},"outputs":[],"source":["!git clone https://github.com/gjuuuy/MT_base.git"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd MT_base"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj5nn1CW9vJd"},"outputs":[],"source":["%pip install datasets OpenNMT-py sentencepiece\n","%pip install --no-cache-dir https://github.com/RobotsMali-AI/rmai/releases/download/0.0.4/rmaipkg-0.0.4.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python scripts/filter.py data/train.bam data/train.fr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python scripts/unigram.py data/train.bam.fil.txt data/train.fr.fil.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mv *.vocab data && mv *.model data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python scripts/subword.py data/source.model data/target.model data/train.bam.fil.txt data/train.fr.fil.txt\n","!python scripts/subword.py data/source.model data/target.model data/dev.bam data/dev.fr\n","!python scripts/subword.py data/source.model data/target.model data/test.bam data/test.fr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mv data/train.sub-src.txt data/train.sub.bam && mv data/train.sub-trg.txt data/train.sub.fr\n","!mv data/dev.sub-src.txt data/dev.sub.bam && mv data/dev.sub-trg.txt data/dev.sub.fr\n","!mv data/test.sub-src.txt data/test.sub.bam && mv data/test.sub-trg.txt data/test.sub.fr"]},{"cell_type":"markdown","metadata":{"id":"31VoxzGqHY8d"},"source":["## Model / Training Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6KKFqB0HeaH"},"outputs":[],"source":["import os\n","\n","model_name = \"bam2fr\"\n","vocab_size = 50000\n","\n","training_steps = 25000\n","valid_steps = int(training_steps / 5)\n","save_ckpt_freq = int(training_steps / 5)\n","warmup_steps = int(training_steps / 10)\n","reporting =  10 # int(training_steps/10)\n","GPU = 1 # TOGGLE for GPU\n","\n","if(not os.path.exists(model_name)):\n","  os.makedirs(model_name)\n","\n","config = f\"\"\"\n","\n","# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: run\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: data/train.sub.bam\n","        path_tgt: data/train.sub.fr\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: data/dev.bam\n","        path_tgt: data/dev.fr\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: models/{model_name}/run/source.vocab\n","tgt_vocab: models/{model_name}/run/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 50000\n","tgt_vocab_size: 50000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: data/source.model\n","tgt_subword_model: data/target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: models/{model_name}\n","\n","# Stop training if it does not imporve after n validations\n","early_stopping: 3\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: {save_ckpt_freq}\n","\n","# To save space, limit checkpoints to last n\n","keep_checkpoint: 2\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps \n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: {training_steps}\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: {valid_steps}\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 1000\n","report_every: {reporting}\n","\n","# Number of GPUs, and IDs of GPUs\n","#world_size: 2\n","#gpu_ranks: [0, 1]\n","\n","# Batching\n","# bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 1024   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 2048\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","\n","\"\"\"\n","\n","if(GPU):\n","  config += \"\"\"\n","world_size: 1\n","gpu_ranks: [0]\n","  \"\"\"\n","\n","with open(f\"{model_name}/config.yaml\", \"w\") as fp:\n","  fp.write(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv8QoZU5TZ8l"},"outputs":[],"source":["!onmt_build_vocab -c bam2fr/config.yaml -n_sample -1 --dump_samples # -1 full corpus, bpe, sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HQ3cHg9VItn"},"outputs":[],"source":["!onmt_build_vocab -config {model_name}/config.yaml -n_sample -1 -num_threads 2"]},{"cell_type":"markdown","metadata":{"id":"kQHRzhIEZTRC"},"source":["## Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-qSMFQ0Za3T"},"outputs":[],"source":["!onmt_translate -model bam2fr/models/bam2fr_step_10000.pt -src data/test.sub-src.txt -output bam2fr/models/pred_10000.txt -gpu -1 -verbose"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45lJ9vy6y5w1"},"outputs":[],"source":["!python scripts/desubword.py data/target.model bam2fr/models/pred_10000.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47sp8qSWAt6q"},"outputs":[],"source":["# Sacrebleu testing CODE\n","bleu = !sacrebleu data/test.fr -i bam2fr/models/pred_10000.txt.desub.txt -m bleu -b -w 4\n","ter = !sacrebleu data/test.fr -i bam2fr/models/pred_10000.txt.desub.txt -m ter -b -w 4\n","\n","print(bleu)\n","print(ter)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM6b4yS0zDXa9ZLcWoPg/na","mount_file_id":"1Un-ObQG6c9zQN03nq4ugkDzCNOblwyve","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"onmt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"vscode":{"interpreter":{"hash":"3817ddb84c541c333c608c08e8d65a77181da8d4c3693ad20cf54437f03f9188"}}},"nbformat":4,"nbformat_minor":0}
